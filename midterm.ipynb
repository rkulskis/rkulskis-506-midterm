{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e35909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import opinion_lexicon\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05677300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914403</td>\n",
       "      <td>B0009W5KHM</td>\n",
       "      <td>AV6QDP8Q0ONK4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1341014400</td>\n",
       "      <td>GOOD FUN FILM</td>\n",
       "      <td>While most straight to DVD films are not worth...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354887</td>\n",
       "      <td>6303079709</td>\n",
       "      <td>A2I8RXJN80A2D2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1168819200</td>\n",
       "      <td>Movie Review</td>\n",
       "      <td>I have wanted this one for sometime, also.  I ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1407653</td>\n",
       "      <td>B004H0M2XC</td>\n",
       "      <td>A3FHV3RV8Z12E6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1386201600</td>\n",
       "      <td>When is it a good time to Consent?</td>\n",
       "      <td>Actually this was a pretty darn good indie fil...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377458</td>\n",
       "      <td>B003ZJ9536</td>\n",
       "      <td>A12VLTA3ZHVPUY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1348704000</td>\n",
       "      <td>TRUTH</td>\n",
       "      <td>Episodes 37 to 72 of the series press on in a ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>475323</td>\n",
       "      <td>630574453X</td>\n",
       "      <td>A13NM1PES9OXVN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>970012800</td>\n",
       "      <td>Intelligent and bittersweet -- stays with you</td>\n",
       "      <td>I was really impressed with this movie, but wa...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
       "0   914403  B0009W5KHM   AV6QDP8Q0ONK4                     2   \n",
       "1   354887  6303079709  A2I8RXJN80A2D2                     0   \n",
       "2  1407653  B004H0M2XC  A3FHV3RV8Z12E6                     0   \n",
       "3  1377458  B003ZJ9536  A12VLTA3ZHVPUY                     1   \n",
       "4   475323  630574453X  A13NM1PES9OXVN                     2   \n",
       "\n",
       "   HelpfulnessDenominator        Time  \\\n",
       "0                       2  1341014400   \n",
       "1                       0  1168819200   \n",
       "2                       0  1386201600   \n",
       "3                       1  1348704000   \n",
       "4                       3   970012800   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                                  GOOD FUN FILM   \n",
       "1                                   Movie Review   \n",
       "2             When is it a good time to Consent?   \n",
       "3                                          TRUTH   \n",
       "4  Intelligent and bittersweet -- stays with you   \n",
       "\n",
       "                                                Text  Score  \n",
       "0  While most straight to DVD films are not worth...    5.0  \n",
       "1  I have wanted this one for sometime, also.  I ...    5.0  \n",
       "2  Actually this was a pretty darn good indie fil...    4.0  \n",
       "3  Episodes 37 to 72 of the series press on in a ...    5.0  \n",
       "4  I was really impressed with this movie, but wa...    3.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527e4485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cd3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached data from: train_with_ratios.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def positive_negative_ratio(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0  # neutral sentiment\n",
    "\n",
    "    scores = sia.polarity_scores(text)\n",
    "    positive_count = scores['pos']\n",
    "    negative_count = scores['neg']\n",
    "\n",
    "    if positive_count + negative_count == 0:\n",
    "        return 0.0  # neutral sentiment\n",
    "\n",
    "    return positive_count / (positive_count + negative_count) # otherwise ratio\n",
    "\n",
    "cached_filename = 'train_with_ratios.csv'\n",
    "\n",
    "# cache data files to save computational time for researching different model params\n",
    "if os.path.exists(cached_filename):\n",
    "    train = pd.read_csv(cached_filename)\n",
    "    print(\"Loaded cached data from:\", cached_filename)\n",
    "else:\n",
    "    train['PosNegRatio'] = train['Text'].apply(positive_negative_ratio)\n",
    "    train['HelpfulnessRatio'] = train['HelpfulnessNumerator'] / (train['HelpfulnessDenominator'] + 1e-5)\n",
    "\n",
    "    columns_to_save = ['Id', 'PosNegRatio', 'HelpfulnessRatio', 'Score']\n",
    "    train[columns_to_save].to_csv(cached_filename, index=False)\n",
    "    print(f\"Calculated and saved data to: {cached_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d23e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib  # to save models\n",
    "\n",
    "train = pd.read_csv('train_with_ratios.csv')\n",
    "train_set = train[~train['Id'].isin(test['Id'])] # remove test ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be013353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Distribution of Scores:\n",
      "   Score   Count\n",
      "0    1.0   91190\n",
      "1    2.0   89678\n",
      "2    3.0  176082\n",
      "3    4.0  335228\n",
      "4    5.0  793163\n",
      "Class Weights: {1.0: 16.28841978287093, 2.0: 16.563047793215727, 3.0: 8.43550732045297, 4.0: 4.430838116147815, 5.0: 1.8726806469792463}\n"
     ]
    }
   ],
   "source": [
    "# to visualize distribution for possible weights in the model\n",
    "score_distribution = train_set.groupby('Score').size().reset_index(name='Count')\n",
    "\n",
    "print(\"Data Distribution of Scores:\")\n",
    "print(score_distribution)\n",
    "\n",
    "counts = dict(zip(score_distribution['Score'], score_distribution['Count']))\n",
    "total_samples = score_distribution['Count'].sum()\n",
    "class_weights = {score: total_samples / count for score, count in counts.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe001740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "X = train_set[['PosNegRatio', 'HelpfulnessRatio']]\n",
    "y = train_set['Score'].astype(int)  # ensure int for classification\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.9, random_state=42)\n",
    "\n",
    "param_grid = { # for CV search\n",
    "    'n_estimators': [100, 200, 500], \n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "def print_progress_search(cv_results):\n",
    "    for i, params in enumerate(cv_results['params']):\n",
    "        mean_score = cv_results['mean_test_score'][i]\n",
    "        print(f\"Model {i + 1}: {params} => Accuracy: {mean_score:.4f}\")\n",
    "\n",
    "# search for cached model        \n",
    "model_filename = 'best_rf_model.joblib'\n",
    "best_params_filename = 'best_params.json'\n",
    "try:\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"Loading cached model...\")\n",
    "        rf_random = joblib.load(model_filename)\n",
    "    else:\n",
    "        raise FileNotFoundError  # trigger exception to train a new model\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"No cached model found. Training a new model...\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_random = RandomizedSearchCV(rf, param_grid, n_iter=10, cv=3, random_state=42, n_jobs=2, verbose=2)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    print_progress_search(rf_random.cv_results_)\n",
    "    joblib.dump(rf_random, model_filename) # save optimal model\n",
    "    print(f\"Model saved to {model_filename}.\")\n",
    "    \n",
    "    best_params = rf_random.best_params_\n",
    "    with open(best_params_filename, 'w') as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "        print(f\"Best parameters saved to {best_params_filename}.\")\n",
    "\n",
    "y_pred = rf_random.predict(X_val)\n",
    "\n",
    "# model evaluation\n",
    "print(\"validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nclassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "print(\"\\nconfusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaecb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = train[train['Id'].isin(test['Id'])] # for creating submission.csv\n",
    "X_test = test_set[['PosNegRatio', 'HelpfulnessRatio']]\n",
    "\n",
    "predicted_scores = rf_random.predict(X_test)\n",
    "rounded_scores = np.clip(np.round(predicted_scores), 1, 5).astype(float)\n",
    "\n",
    "submission_df = pd.DataFrame({ # matches format of submission.csv\n",
    "    'Id': test_set['Id'],\n",
    "    'Score': rounded_scores\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"saved submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14aab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
